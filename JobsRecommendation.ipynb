{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashivashankars/Team_4Musketeers_capstone_project/blob/main/JobsRecommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmIUFYBOAVyL",
        "outputId": "ba7f5afe-e166-4e65-d521-eac291a6c6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.4/132.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -qU pip chromadb sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIK4h4-JAfnG"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evShLIYxAVyM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508,
          "referenced_widgets": [
            "481982028f144a58883733cfdd082a32",
            "e1767a836000401cbcc8c10ea3d65eb1",
            "3f08cccabfd847a088e7d6951c03c7bb",
            "cc6dfd8ed416439eb393701d43a4fcd2",
            "82fc18243495424ca41141ee7a79d995",
            "be9e639e0e154aa7bddea0b8e82510db",
            "c6334ec986804c9ca17859c55aae5785",
            "6867463e52614fd685a43c49e710383f",
            "b55d1c1497f142639f6665bf8ef4f36a",
            "4203808c829b45f8afe1a2d170cd88af",
            "60b8dde5429e461faf776eb06bfba22d",
            "c558ddd829b84bd7a997f94f4de441f8",
            "367227a484b24ead851d50c669abdd86",
            "9988b851846f4cd8bfc22d90d0c4d6fc",
            "576806cbcc8e43e5b49cb1d359a3bfd3",
            "a4792360d2eb4916bb3d06c2d600aada",
            "8337af7d6cfd4d2a9beacebc1bf38f8a",
            "1285fa5439504c00893f45808a75b2ee",
            "a2e331e0fdee4dcb98353ad774362554",
            "531aa64e419d4a04bb11abfeda2e2857",
            "30839682385b458a885dca1086b6cc49",
            "e11811268733475f9a0d4cbac619e1af",
            "e272082bf9f84d3a80e3e8581e2047b7",
            "bd9a6dd016404e76b7ed8ee54f0620d2",
            "2c8654a1ac944e2f92534756cccdfcca",
            "339b3df6096b408f80205f89335942f0",
            "654b8881568c40628da0c0020c4b5b67",
            "91363423a6434a5d80d58289fc5d615a",
            "3ac3cd059afb4da7bd816ff66021da14",
            "a7a1873fcd6c4ddeac58afbd88ba9d18",
            "022b3d9d917c4cfd9e9ed58585c6f03e",
            "ef12d541da4b457e9a9dbb958fd5006c",
            "913a2bcca7d34d9aa9ee2a0f8a7f64cd",
            "42afb5a3cb2243ac9fd2ae9ee341ce0e",
            "1d87a3b384924c38b9de493977864587",
            "4c3329b287d3400e8dc59bbffa9ad8e5",
            "0ce1e244d98c48bca83d8cc32e17bf99",
            "b6450193233a40d4a4d70f44d8b14e15",
            "d4a4e061048642819144c566308721b9",
            "7cbc9b51298e4397b45d56893d99fc2e",
            "356da254a76746e19af4ad4d5473a029",
            "fbb20ea59e6048d3a3788730d017ebd3",
            "8062dcdbf99c4da6b4d3438a8498c8e3",
            "a8a2918624e245aa99d4ec42ff9e3311",
            "cedfd8b72c474771a5e1554e6ea33bc8",
            "05f15eb0bcc34fa782cf45b7e271638b",
            "2460c618c8b14639b97dbd4522a9a277",
            "8cb82f18a0ec4b7ca9bb98ed4021fee6",
            "9e8856b9efa147d69396b52c925b51ea",
            "1842cdde8e9e41fa8024365e105438fd",
            "700ef726221b40de92120452b7342f11",
            "0e5bc0e4eb9c40989ea95e9c348a3812",
            "acd8068f8e494f5180f72e65b28fad43",
            "8b818af4be9146069ece688920241c0e",
            "30215e196da24acdbb89db17c28771c8",
            "e04fc42bca464e6f868e738a561653fc",
            "df4510c5f91b45bfbb2af141a0ad9285",
            "298086b79edb4de7b983fa6b7dcee129",
            "a9e20dd45f024bb1a18c5598a03f301a",
            "7afc66b3baf4490a9e1898423e7955df",
            "ceff9a557e7c48a8be5a4151b31c2856",
            "d0819052c3a846c4aa76594d859c9374",
            "752765f9102946b4a727b7dafbf9f37c",
            "b060b576a47d42b2b56bc03b6c1a2256",
            "91f5d9400fe345989f49c8b2f12b1318",
            "0fc55ae234614f338b77afe692488505",
            "9f850c7aa7054e83896fa58e6ab64a04",
            "69a537df967a4d37924d4ea815811016",
            "6f44b884b55f4fca8afb97900f2dbb81",
            "81ee24daec7543e985c7284087e2ef29",
            "9e6ef6488f4a42b9adfa23d0d7dc7c04",
            "b3e4d0a241ec41e48d4ee3cbbece0e44",
            "9a6c3059d8044d3bab08f2b955791337",
            "fd0dca9cbc514797bde210b40f9d8383",
            "f97e954e572744b9adbf487ced7fa42c",
            "b834add160254d56b90c4d0dc67e912d",
            "d2227aa9785c41e79fee884dfd4f7d4c",
            "e5c9e44b91a94c89ad46138acc089650",
            "3df7b4084585411989d91cf2c53e913c",
            "3563ae1c2a194955a42a535ea94a7682",
            "e57f05db8a184b66b7e493ed6c7190c7",
            "4702467fffe04850a635f7985b56413c",
            "801c48b519db403b9379a1a0e781d618",
            "0315d6f8cd7e43c1b39593521a269af2",
            "23da3ab9dde842ddb341ee4c0a42fda0",
            "c984fbc79e4549c09c0529435e557615",
            "b084bc0653a0424baaa17d530ee99937",
            "def76e9a815e4bd1b8528e993497d2b6",
            "256396d08e1746549e115df2ebfde3cb",
            "52fd304ae66e4097b134b3c3bcbbd3fe",
            "dcb1d488f645479dad7fe9d488b779bf",
            "5fa72872824845e7a8766c4c993907d5",
            "8f330738d9af4e648e032df7ea4f16d9",
            "0f84c2e5d1744e159aaebe86fefc8bc9",
            "a8f89918c5f141349587d47ca95aa484",
            "9d6ef325cefc4495ab31af40edb14522",
            "90ff1f2591a948cc9a4d7f8280d5f79e",
            "69418c777a344a02b04e9977f623bad3",
            "9586f866cbbd49c0aa987708e54dfd22",
            "4920bf4cc37744f09dc3851d3216a7c1",
            "ed22cb13649540719adc5d9ade3504d2",
            "e2304c62afda4d2595f1355a7c9b7cfd",
            "9747fa9774ba4d8bb3535fbed2592188",
            "77515d637af94d9b99403437b277360a",
            "aebf8af22dfc4a6886660b542a977094",
            "6f5b537b87d1484fa576acc4baad1041",
            "7d99144b9b5f458a8c35413200e91be2",
            "fc7a95b94d434ac3a3d3db7b3ee35d1f",
            "f57bb71fb30a4af0af86d290318a8087",
            "658e3c2e68664676a9f2c4964b30ee80",
            "d1fc13534da4434a9ebcff503c619a9f",
            "ff156336896349f2884b870fdf1c3870",
            "4cbac24e31a845eda7970b5fc5f84c0f",
            "9b7ef623b7a64fc2b51e706a506bc26c",
            "59378d5b2e274fe49dcfa36c8b480354",
            "0ad0112ef85e4b0c9005f8d78cec76e0",
            "a2b609d65298498a8008f94e23a80108",
            "02635dc1b2e746cfa8d3aeca0b4a1596",
            "206d79541f454509a57f6efe5bca57ab",
            "d5ae50d50ec04d8da305f3fa0b9caba0",
            "f356d0d6d9f841cd94ed5a9d5a34a196"
          ]
        },
        "id": "K_L4Gn3UAVyM",
        "outputId": "f7be0ebc-6872-4f77-fb52-aa196e9c40ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "481982028f144a58883733cfdd082a32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c558ddd829b84bd7a997f94f4de441f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e272082bf9f84d3a80e3e8581e2047b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42afb5a3cb2243ac9fd2ae9ee341ce0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cedfd8b72c474771a5e1554e6ea33bc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e04fc42bca464e6f868e738a561653fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f850c7aa7054e83896fa58e6ab64a04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5c9e44b91a94c89ad46138acc089650",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "256396d08e1746549e115df2ebfde3cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4920bf4cc37744f09dc3851d3216a7c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1fc13534da4434a9ebcff503c619a9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- 1. SETUP AND CONFIGURATION ---\n",
        "\n",
        "# Path for Persistent DB (Simulated for local environment)\n",
        "from google.colab import drive # Uncomment if running in Colab\n",
        "drive.mount('/content/drive')\n",
        "DB_PATH = '/content/drive/MyDrive/demoDB'\n",
        "\n",
        "# Initialize Embedding Model\n",
        "EMBEDDING_MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "EMBEDDING_DIM = EMBEDDING_MODEL.get_sentence_embedding_dimension()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-fl4G63SLDZ"
      },
      "source": [
        "#Set up vector embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RbS4LyuAVyM"
      },
      "outputs": [],
      "source": [
        "# --- 2. HELPERS ---\n",
        "\n",
        "def resolve_degree_rank(degree_input):\n",
        "    \"\"\"\n",
        "    Parses degree strings robustly to return an integer rank.\n",
        "    Ranks: 0=None, 1=Bachelor, 2=Master, 3=PhD\n",
        "    \"\"\"\n",
        "    if pd.isna(degree_input) or not isinstance(degree_input, str):\n",
        "        return 0\n",
        "\n",
        "    text = degree_input.lower().strip()\n",
        "\n",
        "    # 3 - PhD / Doctorate\n",
        "    if re.search(r'\\b(phd|p\\.h\\.d|doctorate|doc|dr|m.d)\\b', text):\n",
        "        return 3\n",
        "\n",
        "    # 2 - Master's\n",
        "    if re.search(r'\\b(master|m\\.s|msc|m\\.a|mba)\\b', text):\n",
        "        return 2\n",
        "\n",
        "    # 1 - Bachelor's\n",
        "    if re.search(r'\\b(bachelor|b\\.s|bsc|b\\.a)\\b', text):\n",
        "        return 1\n",
        "\n",
        "    return 0\n",
        "\n",
        "\n",
        "class ThermometerEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Encodes categorical levels as cumulative vectors using the robust resolver.\n",
        "    Bachelor (Rank 1) -> [1, 0, 0]\n",
        "    Master   (Rank 2) -> [1, 1, 0]\n",
        "    PhD      (Rank 3) -> [1, 1, 1]\n",
        "    \"\"\"\n",
        "    def __init__(self, max_rank=3):\n",
        "        self.max_rank = max_rank\n",
        "\n",
        "    def fit(self, X, y=None): return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        vectors = []\n",
        "        data_col = X.iloc[:, 0] if hasattr(X, 'iloc') else X[:, 0]\n",
        "\n",
        "        for degree in data_col:\n",
        "            rank = resolve_degree_rank(degree)\n",
        "            vec = [1 if i < rank else 0 for i in range(self.max_rank)]\n",
        "            vectors.append(vec)\n",
        "\n",
        "        return np.array(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0CW6vtZAVyN"
      },
      "outputs": [],
      "source": [
        "# --- 3. FEATURE ENGINEERING PIPELINE ---\n",
        "\n",
        "class FeatureVectorization:\n",
        "    def __init__(self, embedding_model):\n",
        "        self.embedding_model = embedding_model\n",
        "        self.preprocessor = None\n",
        "\n",
        "    def _create_preprocessor(self):\n",
        "        # Features that will be included in the vector for Cosine Similarity:\n",
        "        # 1. Numerical Pipeline (YOE)\n",
        "        numerical_features = ['YOE']\n",
        "        numerical_transformer = Pipeline(steps=[\n",
        "            ('scaler', MinMaxScaler())\n",
        "        ])\n",
        "\n",
        "        # 2. Custom Pipeline (Diploma)\n",
        "        categorical_features = ['Diploma']\n",
        "        categorical_transformer = Pipeline(steps=[\n",
        "            ('thermometer', ThermometerEncoder())\n",
        "        ])\n",
        "\n",
        "        # Combine ONLY the features needed for similarity ranking\n",
        "        self.preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', numerical_transformer, numerical_features),\n",
        "                ('cat', categorical_transformer, categorical_features)\n",
        "            ],\n",
        "            # CRITICAL: 'drop' ensures Job_type, Sponsorship, etc., are NOT vectorized\n",
        "            remainder='drop'\n",
        "        )\n",
        "\n",
        "    def fit_transform(self, df):\n",
        "        self._create_preprocessor()\n",
        "\n",
        "        # 1. Transform structured data (YOE + Thermometer Diploma)\n",
        "        structured_features = self.preprocessor.fit_transform(df)\n",
        "        if hasattr(structured_features, \"toarray\"):\n",
        "            structured_features = structured_features.toarray()\n",
        "\n",
        "        # 2. Calculate Skill Embeddings (The dominant part of the vector)\n",
        "        print(f\"Generating text embeddings for {len(df)} entries...\")\n",
        "        skill_embeddings = self.embedding_model.encode(df['skill_sets'].tolist())\n",
        "\n",
        "        # 3. Concatenate everything\n",
        "        composite_vectors = np.hstack([structured_features, skill_embeddings])\n",
        "        return composite_vectors\n",
        "\n",
        "    def transform_candidate(self, candidate_dict):\n",
        "        # Helper to transform a single candidate dictionary\n",
        "        df_cand = pd.DataFrame([candidate_dict])\n",
        "\n",
        "        # 1. Structure\n",
        "        structured = self.preprocessor.transform(df_cand)\n",
        "        if hasattr(structured, \"toarray\"): structured = structured.toarray()\n",
        "\n",
        "        # 2. Text\n",
        "        text_emb = self.embedding_model.encode(df_cand['skill_sets'].iloc[0])\n",
        "\n",
        "        # 3. Combine\n",
        "        return np.hstack([structured, text_emb.reshape(1, -1)])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5acMnGjnAVyN"
      },
      "outputs": [],
      "source": [
        "# --- 4. FILTER LOGIC HELPERS ---\n",
        "\n",
        "def get_sponsorship_filter(candidate_sponsorship_status):\n",
        "    \"\"\"\n",
        "    Logic:\n",
        "    If Candidate Requires Sponsorship (True) -> They can only apply to jobs that provide it (True).\n",
        "    If Candidate Does NOT Require (False) -> They can apply to anything (True or False).\n",
        "    \"\"\"\n",
        "    if candidate_sponsorship_status == True:\n",
        "        return {\"Provide_Sponsorship\": {\"$eq\": True}}\n",
        "    else:\n",
        "        # Candidate is local/has visa. Can take jobs that sponsor OR jobs that don't.\n",
        "        return {\"$or\": [{\"Provide_Sponsorship\": {\"$eq\": True}}, {\"Provide_Sponsorship\": {\"$eq\": False}}]}\n",
        "\n",
        "def get_job_type_filter(candidate_job_type):\n",
        "    \"\"\"\n",
        "    Logic:\n",
        "    'Both' -> Matches 'Intern' OR 'Full-Time'.\n",
        "    Otherwise -> Exact Match.\n",
        "    \"\"\"\n",
        "    if candidate_job_type.lower() == 'both':\n",
        "        return {\"$or\": [{\"Job_type\": \"Intern\"}, {\"Job_type\": \"Full-Time\"}]}\n",
        "    else:\n",
        "        return {\"Job_type\": {\"$eq\": candidate_job_type}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAOiqghfPr6e"
      },
      "source": [
        "#Loading Job posting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j04VUvYbOoVq",
        "outputId": "70b84788-1609-4bf4-cac5-4c288f3bbe0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   job_id                  Company                               Role  \\\n",
            "0       0  The Walt Disney Company                Data Product Intern   \n",
            "1       1                Teamworks          Product Management Intern   \n",
            "2       2                  Zscaler     Product Management Intern - AI   \n",
            "3       3              ğŸ”¥ServiceNow         Portfolio Associate Intern   \n",
            "4       4                Santander  Digital Product Management Intern   \n",
            "\n",
            "                                                 url  YOE      Diploma  \\\n",
            "0  https://disney.wd5.myworkdayjobs.com/disneycar...  0.0          NaN   \n",
            "1  https://ats.rippling.com/teamworks-careers/job...  3.0       Master   \n",
            "2  https://job-boards.greenhouse.io/zscaler/jobs/...  0.0  High School   \n",
            "3  https://jobs.smartrecruiters.com/ServiceNow/74...  0.0  High School   \n",
            "4  https://santander.wd3.myworkdayjobs.com/Santan...  0.0          NaN   \n",
            "\n",
            "  Job_type  Provide_Sponsorship  \\\n",
            "0   Intern                 True   \n",
            "1   Intern                 True   \n",
            "2   Intern                 True   \n",
            "3   Intern                 True   \n",
            "4   Intern                 True   \n",
            "\n",
            "                                          skill_sets  degree_rank  \n",
            "0  ['Big Data & Processing', 'Business/Analysis',...            0  \n",
            "1  ['API/Architecture', 'Automated Testing & QA',...            2  \n",
            "2  ['API/Architecture', 'Business/Analysis', 'C#/...            0  \n",
            "3  ['API/Architecture', 'Automated Testing & QA',...            0  \n",
            "4  ['Business/Analysis', 'Communication & Soft Sk...            0  \n"
          ]
        }
      ],
      "source": [
        "jobs_df = pd.read_csv('/content/drive/MyDrive/jobs_df_demo.csv')\n",
        "print(jobs_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQDdPt5WKDBa",
        "outputId": "9809e8fd-2ac7-4afe-c06f-006691d362c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   job_id                  Company                               Role  \\\n",
            "0       0  The Walt Disney Company                Data Product Intern   \n",
            "1       1                Teamworks          Product Management Intern   \n",
            "2       2                  Zscaler     Product Management Intern - AI   \n",
            "3       3              ğŸ”¥ServiceNow         Portfolio Associate Intern   \n",
            "4       4                Santander  Digital Product Management Intern   \n",
            "\n",
            "                                                 url  YOE      Diploma  \\\n",
            "0  https://disney.wd5.myworkdayjobs.com/disneycar...  0.0          NaN   \n",
            "1  https://ats.rippling.com/teamworks-careers/job...  3.0       Master   \n",
            "2  https://job-boards.greenhouse.io/zscaler/jobs/...  0.0  High School   \n",
            "3  https://jobs.smartrecruiters.com/ServiceNow/74...  0.0  High School   \n",
            "4  https://santander.wd3.myworkdayjobs.com/Santan...  0.0          NaN   \n",
            "\n",
            "  Job_type  Provide_Sponsorship  \\\n",
            "0   Intern                 True   \n",
            "1   Intern                 True   \n",
            "2   Intern                 True   \n",
            "3   Intern                 True   \n",
            "4   Intern                 True   \n",
            "\n",
            "                                          skill_sets  degree_rank  \n",
            "0  ['Big Data & Processing', 'Business/Analysis',...            0  \n",
            "1  ['API/Architecture', 'Automated Testing & QA',...            2  \n",
            "2  ['API/Architecture', 'Business/Analysis', 'C#/...            0  \n",
            "3  ['API/Architecture', 'Automated Testing & QA',...            0  \n",
            "4  ['Business/Analysis', 'Communication & Soft Sk...            0  \n"
          ]
        }
      ],
      "source": [
        "def update_job_type(row):\n",
        "    if re.search(r'intern', str(row['Role']), re.IGNORECASE):\n",
        "        return 'Intern'\n",
        "    return 'Full-Time'\n",
        "\n",
        "jobs_df['Job_type'] = jobs_df.apply(update_job_type, axis=1)\n",
        "print(jobs_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysJsZZZcKjED",
        "outputId": "f45128e0-0cb1-4643-a3e8-dd59d7387bc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1582\n",
            "Number of rows with 'Intern' in 'Job_type': 1092\n"
          ]
        }
      ],
      "source": [
        "print(len(jobs_df))\n",
        "intern_count = jobs_df[jobs_df['Job_type'] == 'Intern'].shape[0]\n",
        "print(f\"Number of rows with 'Intern' in 'Job_type': {intern_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjsn5M9HO4PY",
        "outputId": "e7b0d17e-c494-4bf7-81bc-9227cc2cda48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   job_id                  Company                               Role  \\\n",
            "0       0  The Walt Disney Company                Data Product Intern   \n",
            "1       1                Teamworks          Product Management Intern   \n",
            "2       2                  Zscaler     Product Management Intern - AI   \n",
            "3       3              ğŸ”¥ServiceNow         Portfolio Associate Intern   \n",
            "4       4                Santander  Digital Product Management Intern   \n",
            "\n",
            "                                                 url  YOE      Diploma  \\\n",
            "0  https://disney.wd5.myworkdayjobs.com/disneycar...  0.0          NaN   \n",
            "1  https://ats.rippling.com/teamworks-careers/job...  3.0       Master   \n",
            "2  https://job-boards.greenhouse.io/zscaler/jobs/...  0.0  High School   \n",
            "3  https://jobs.smartrecruiters.com/ServiceNow/74...  0.0  High School   \n",
            "4  https://santander.wd3.myworkdayjobs.com/Santan...  0.0          NaN   \n",
            "\n",
            "  Job_type  Provide_Sponsorship  \\\n",
            "0   Intern                 True   \n",
            "1   Intern                 True   \n",
            "2   Intern                 True   \n",
            "3   Intern                 True   \n",
            "4   Intern                 True   \n",
            "\n",
            "                                          skill_sets  degree_rank  \n",
            "0  ['Big Data & Processing', 'Business/Analysis',...            0  \n",
            "1  ['API/Architecture', 'Automated Testing & QA',...            2  \n",
            "2  ['API/Architecture', 'Business/Analysis', 'C#/...            0  \n",
            "3  ['API/Architecture', 'Automated Testing & QA',...            0  \n",
            "4  ['Business/Analysis', 'Communication & Soft Sk...            0  \n"
          ]
        }
      ],
      "source": [
        "jobs_df['degree_rank'] = jobs_df['Diploma'].apply(resolve_degree_rank)\n",
        "print(jobs_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjxmIqGbSTew"
      },
      "outputs": [],
      "source": [
        "# jobs_df.to_csv('jobs_df_demo.csv', index=False)\n",
        "# print(\"jobs_df saved to jobs_df_demo.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWHdSkK-TfCN"
      },
      "source": [
        "#Load VecDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk8MkboKAVyN",
        "outputId": "dd4a655a-1567-42b9-e4cd-bcba671c0a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorizing and Ingesting Data...\n",
            "Generating text embeddings for 1582 entries...\n",
            "Ingestion complete.\n"
          ]
        }
      ],
      "source": [
        "from chromadb import Client, PersistentClient, Settings\n",
        "\n",
        "# --- CHROMA DB INIT ---\n",
        "# if os.path.exists(DB_PATH):\n",
        "#     shutil.rmtree(DB_PATH)\n",
        "\n",
        "client = PersistentClient(path=DB_PATH) #for demo\n",
        "\n",
        "# client = Client(Settings(allow_reset=True)) #for dev\n",
        "# client.reset()\n",
        "\n",
        "COLLECTION_NAME = \"job_postings_demo\"\n",
        "\n",
        "collection = client.get_or_create_collection(\n",
        "    name=COLLECTION_NAME,\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "if collection.count() == 0:\n",
        "    print(\"Vectorizing and Ingesting Data...\")\n",
        "\n",
        "    vectorizer = FeatureVectorization(EMBEDDING_MODEL)\n",
        "    job_vectors = vectorizer.fit_transform(jobs_df)\n",
        "\n",
        "    # Metadata: Store ALL fields needed for display + degree_rank for filtering\n",
        "    metadatas = jobs_df.apply(lambda row: {\n",
        "        'Company': row['Company'],\n",
        "        'Role': row['Role'],\n",
        "        'YOE': row['YOE'],\n",
        "        'Diploma': row['Diploma'],\n",
        "        'Job_type': row['Job_type'],\n",
        "        'skill_sets': row['skill_sets'],\n",
        "        'Provide_Sponsorship': row['Provide_Sponsorship'],\n",
        "        'url': row['url'],\n",
        "        'min_degree_req': row['degree_rank']\n",
        "    }, axis=1).tolist()\n",
        "\n",
        "    # Generate unique IDs from the DataFrame index\n",
        "    job_ids = [str(i) for i in jobs_df.index.tolist()]\n",
        "\n",
        "    collection.add(\n",
        "        embeddings=job_vectors.tolist(),\n",
        "        documents=jobs_df['skill_sets'].tolist(),\n",
        "        metadatas=metadatas,\n",
        "        ids=job_ids # Uncommented and provided ids\n",
        "    )\n",
        "    print(\"Ingestion complete.\")\n",
        "else:\n",
        "    print(\"Loaded existing data.\")\n",
        "    # Re-init vectorizer for candidate transform\n",
        "    vectorizer = FeatureVectorization(EMBEDDING_MODEL)\n",
        "    vectorizer.fit_transform(jobs_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKC6E4c5bAYg"
      },
      "source": [
        "#Feed candidate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uxA1C6Ka4HE"
      },
      "outputs": [],
      "source": [
        "def match_jobs_from_csv(candidates_df):\n",
        "    all_results = []\n",
        "    for index, row in candidates_df.iterrows():\n",
        "        candidate_profile = {\n",
        "            'YOE': row['YOE'],\n",
        "            'Diploma': row['Diploma'],\n",
        "            'skill_sets': row['skill_sets'],\n",
        "            'Job_type': row['Job_type'],\n",
        "            'Require_Sponsorship': row['Require_Sponsorship']\n",
        "        }\n",
        "\n",
        "        print(f\"\\n--- Processing Candidate {index + 1} ---\")\n",
        "        print(candidate_profile)\n",
        "\n",
        "        # 1. Build Filters\n",
        "        cand_rank = resolve_degree_rank(candidate_profile['Diploma'])\n",
        "        diploma_filter = {\"min_degree_req\": {\"$lte\": cand_rank}}\n",
        "        sponsorship_filter = get_sponsorship_filter(candidate_profile['Require_Sponsorship'])\n",
        "        job_type_filter = get_job_type_filter(candidate_profile['Job_type'])\n",
        "\n",
        "        # 2. Combine with $and\n",
        "        combined_filter = {\n",
        "            \"$and\": [\n",
        "                diploma_filter,\n",
        "                sponsorship_filter,\n",
        "                job_type_filter\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # 3. Vectorize\n",
        "        cand_vec = vectorizer.transform_candidate(candidate_profile)\n",
        "\n",
        "        # 4. Query\n",
        "        results = collection.query(\n",
        "            query_embeddings=[cand_vec.tolist()],\n",
        "            n_results=5,\n",
        "            where=combined_filter\n",
        "        )\n",
        "\n",
        "        # 5. Display\n",
        "        print(f\"\\n--- Top Matches for Candidate {index + 1} ---\")\n",
        "        metas = results['metadatas'][0]\n",
        "        dists = results['distances'][0]\n",
        "\n",
        "        results_display = []\n",
        "        if metas:\n",
        "            for i in range(len(metas)):\n",
        "                results_display.append({\n",
        "                    'Candidate_Index': index + 1,\n",
        "                    'Company': metas[i]['Company'],\n",
        "                    'Role': metas[i]['Role'],\n",
        "                    'Score': f\"{1 - dists[i]:.4f}\",\n",
        "                    'Job Type': metas[i]['Job_type'],\n",
        "                    'Provide_Sponsorship': metas[i]['Provide_Sponsorship'],\n",
        "                    'Required Skills': metas[i]['skill_sets'],\n",
        "                    'URL': metas[i]['url']\n",
        "                })\n",
        "        else:\n",
        "            print(\"No matches found for this candidate.\")\n",
        "\n",
        "        if results_display:\n",
        "            all_results.extend(results_display)\n",
        "    response_str = \"\"\n",
        "    if all_results:\n",
        "        final_df = pd.DataFrame(all_results)\n",
        "        response_str = final_df.to_markdown(index=False)\n",
        "        print(response_str)\n",
        "        return response_str\n",
        "    else:\n",
        "        response_str = \"No job matches found for any candidates in the CSV.\"\n",
        "        print(response_str)\n",
        "        return response_str\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elsisrq9c4gS"
      },
      "source": [
        "#AI agent UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaYbDU3-c9SI",
        "outputId": "3ebd53e8-29bf-4517-eade-a742a05eec06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n"
          ]
        }
      ],
      "source": [
        "%pip install gradio google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjAqEtD6dCq0",
        "outputId": "95e2a5a0-6ec6-40c8-b437-5a98412600ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your Google API Key (you can also set it in Colab Secrets named 'GOOGLE_API_KEY'): AIzaSyBTW6E95e9lYsnqmOPltAqcDrhMjmBr1Xw\n",
            "Google Generative AI configured with the provided API key.\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Ask the user for the API key\n",
        "api_key_input = input(\"Please enter your Google API Key (you can also set it in Colab Secrets named 'GOOGLE_API_KEY'): \")\n",
        "\n",
        "# Configure the Generative AI library with the provided key if it's not empty\n",
        "if api_key_input:\n",
        "  genai.configure(api_key=api_key_input)\n",
        "  print(\"Google Generative AI configured with the provided API key.\")\n",
        "else:\n",
        "  print(\"No API key provided directly. The application will attempt to use Colab Secrets or existing configuration.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmbiecs2ddrZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def process_json_to_dataframe(json_data):\n",
        "    \"\"\"\n",
        "    Transforms a candidate profile JSON object into a Pandas DataFrame row.\n",
        "\n",
        "    Args:\n",
        "        json_data (dict): The input JSON object as a Python dictionary.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with the specified columns.\n",
        "    \"\"\"\n",
        "    df_data = {}\n",
        "\n",
        "    # YOE: Convert to numeric, handle 'NULL' as NaN\n",
        "    yoe_str = json_data.get(\"YOE\", \"NULL\")\n",
        "    df_data['YOE'] = pd.to_numeric(yoe_str, errors='coerce')\n",
        "\n",
        "    # Diploma: Get as is\n",
        "    df_data['Diploma'] = json_data.get(\"current_degree_major\", \"NULL\")\n",
        "\n",
        "    # Job_type: Get as is\n",
        "    df_data['Job_type'] = json_data.get(\"job_preference\", \"NULL\")\n",
        "\n",
        "    # Require_Sponsorship: Convert 'Yes' to True, 'No'/'NULL' to False\n",
        "    require_sponsorship_str = json_data.get(\"require_sponsorship\", \"NULL\").lower()\n",
        "    df_data['Require_Sponsorship'] = True if require_sponsorship_str == 'yes' else False\n",
        "\n",
        "    # skill_sets: Combine programming_languages and tools_frameworks into a single string\n",
        "    programming_languages = json_data.get(\"programming_languages\", [])\n",
        "    tools_frameworks = json_data.get(\"tools_frameworks\", [])\n",
        "\n",
        "    # Ensure they are lists and not \"NULL\" string from extraction\n",
        "    if isinstance(programming_languages, str) and programming_languages == \"NULL\":\n",
        "        programming_languages = []\n",
        "    if isinstance(tools_frameworks, str) and tools_frameworks == \"NULL\":\n",
        "        tools_frameworks = []\n",
        "\n",
        "    all_skills = []\n",
        "    if isinstance(programming_languages, list):\n",
        "        all_skills.extend(programming_languages)\n",
        "    if isinstance(tools_frameworks, list):\n",
        "        all_skills.extend(tools_frameworks)\n",
        "\n",
        "    # Filter out empty strings or 'NULL' values, remove duplicates, and join\n",
        "    filtered_skills = [skill.strip() for skill in all_skills if skill and skill.strip() != 'NULL']\n",
        "    df_data['skill_sets'] = \", \".join(sorted(list(set(filtered_skills))))\n",
        "\n",
        "    # Create a DataFrame from a single row dictionary\n",
        "    return pd.DataFrame([df_data])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG6xqOGKdxom"
      },
      "outputs": [],
      "source": [
        "def match_jobs(json_data):\n",
        "  candidate_df = process_json_to_dataframe(json_data)\n",
        "  result = match_jobs_from_csv(candidate_df)\n",
        "  print(result)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLYD6ZWjdlSW"
      },
      "source": [
        "# Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "eaTcJbl0dgTc",
        "outputId": "b04379ee-fb86-4ccb-e41c-3ff35feeefc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3576056910.py:166: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
            "/tmp/ipython-input-3576056910.py:171: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n",
            "/tmp/ipython-input-3576056910.py:171: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://3d4570fce687e8f800.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://3d4570fce687e8f800.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "FIELD_CONFIG = {\n",
        "    \"graduation_date\":      {\"id\": 1, \"text\": \"Expected Graduation Date\", \"mode\": \"interactive\"},\n",
        "    \"current_degree_major\": {\"id\": 2, \"text\": \"Current Degree AND Major (e.g. MS in CS)\", \"mode\": \"interactive\"},\n",
        "    \"current_degree_gpa\":   {\"id\": 3, \"text\": \"GPA (For Current Degree Only)\", \"mode\": \"interactive\"},\n",
        "    \"require_sponsorship\":   {\"id\": 4, \"text\": \"Do you require sponsorhip? (Yes/No)\", \"mode\": \"interactive\"},\n",
        "    \"programming_languages\": {\"id\": 5, \"text\": \"Programming Languages\", \"mode\": \"extract\"},\n",
        "    \"YOE\":                   {\"id\": 6, \"text\": \"How many year of experience do you have?\", \"mode\": \"interactive\"},\n",
        "    \"tools_frameworks\":      {\"id\": 7, \"text\": \"Tools & Frameworks\", \"mode\": \"extract\"},\n",
        "    \"leadership\":            {\"id\": 8, \"text\": \"Leadership Experience\", \"mode\": \"extract\"},\n",
        "    \"job_preference\":        {\"id\": 9, \"text\": \"Looking for Full-time / Internship / Both?\", \"mode\": \"interactive\"},\n",
        "    \"impact_outcomes\":       {\"id\": 10,\"text\": \"Quantifiable Impact & Key Achievements\", \"mode\": \"extract\"}\n",
        "}\n",
        "\n",
        "# --- 2. AGENT CLASS (State Manager) ---\n",
        "class ResumeChatBot:\n",
        "    def __init__(self):\n",
        "        self.api_key = None\n",
        "        self.state = \"INIT\"  # States: INIT, WAITING_FOR_RESUME, VERIFYING, COMPLETE\n",
        "        self.extracted_data = {}\n",
        "        self.missing_queue = [] # List of keys that need verification\n",
        "        self.current_missing_key = None\n",
        "\n",
        "        # Try to load API key immediately\n",
        "        try:\n",
        "            self.api_key = api_key_input\n",
        "            genai.configure(api_key=self.api_key)\n",
        "            self.state = \"WAITING_FOR_RESUME\"\n",
        "        except:\n",
        "            self.state = \"MISSING_KEY\"\n",
        "\n",
        "    def get_intro_message(self):\n",
        "        if self.state == \"MISSING_KEY\":\n",
        "            return \"âš ï¸ Error: GOOGLE_API_KEY not found in Secrets. Please add it to Colab secrets and restart.\"\n",
        "        return \"ğŸ‘‹ Hello! I am your Candidate Profile Agent.\\n\\nPlease **upload your resume (PDF)** to the box on the right to get started.\"\n",
        "\n",
        "    def process_file(self, file_path):\n",
        "        \"\"\"Handles file upload, sends to Gemini, and parses JSON.\"\"\"\n",
        "        if not file_path:\n",
        "            return \"âŒ No file received.\"\n",
        "\n",
        "        if self.state == \"MISSING_KEY\":\n",
        "            return \"âš ï¸ Cannot process: Missing API Key.\"\n",
        "\n",
        "        # 1. Upload to Gemini\n",
        "        try:\n",
        "            # Upload file\n",
        "            gemini_file = genai.upload_file(file_path)\n",
        "\n",
        "            # Wait for processing\n",
        "            while gemini_file.state.name == \"PROCESSING\":\n",
        "                time.sleep(1)\n",
        "                gemini_file = genai.get_file(gemini_file.name)\n",
        "\n",
        "            if gemini_file.state.name != \"ACTIVE\":\n",
        "                return \"âŒ Error processing file on Gemini server.\"\n",
        "\n",
        "            # 2. Extract Data\n",
        "            model = genai.GenerativeModel(\"models/gemini-2.5-flash\") # Using Flash for speed\n",
        "\n",
        "            prompt = \"\"\"\n",
        "            You are a precise data extraction agent. Analyze the attached resume.\n",
        "            Extract the following fields into a JSON object.\n",
        "\n",
        "            STRICT RULES:\n",
        "            - If a field is NOT explicitly found, use the string \"NULL\".\n",
        "            - require_sponsorship: If not found, return \"NULL\".\n",
        "            - JOB PREFERENCE: If not found, return \"NULL\".\n",
        "            - LEADERSHIP: Return a list of objects or \"NULL\".\n",
        "\n",
        "            Required JSON Keys:\n",
        "            graduation_date, current_degree_major, current_degree_gpa, require_sponsorship,\n",
        "            programming_languages, experience_software, tools_frameworks, leadership,\n",
        "            job_preference, impact_outcomes\n",
        "            \"\"\"\n",
        "\n",
        "            response = model.generate_content(\n",
        "                [gemini_file, prompt],\n",
        "                generation_config={\"response_mime_type\": \"application/json\"}\n",
        "            )\n",
        "\n",
        "            self.extracted_data = json.loads(response.text)\n",
        "\n",
        "            # 3. Identify Missing Info\n",
        "            self.missing_queue = []\n",
        "\n",
        "            # Check for blanks (NULL) or empty strings\n",
        "            null_count = 0\n",
        "            for key, config in FIELD_CONFIG.items():\n",
        "                val = self.extracted_data.get(key, \"NULL\")\n",
        "                if val in [\"NULL\", None, \"\"]:\n",
        "                    null_count += 1\n",
        "                    # Only ask interactive questions or if resume is blank\n",
        "                    if config['mode'] == 'interactive' or null_count >= 8:\n",
        "                        self.missing_queue.append(key)\n",
        "\n",
        "            # 4. Transition State\n",
        "            if not self.missing_queue:\n",
        "                self.state = \"COMPLETE\"\n",
        "                return self.finalize_report()\n",
        "            else:\n",
        "                self.state = \"VERIFYING\"\n",
        "                return self.next_question()\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ Error during extraction: {str(e)}\"\n",
        "\n",
        "    def next_question(self):\n",
        "        \"\"\"Pops the next missing field and formulates a question.\"\"\"\n",
        "        if not self.missing_queue:\n",
        "            self.state = \"COMPLETE\"\n",
        "            return self.finalize_report()\n",
        "\n",
        "        self.current_missing_key = self.missing_queue.pop(0)\n",
        "        field_info = FIELD_CONFIG[self.current_missing_key]\n",
        "        return f\"I couldn't find your **{field_info['text']}** in the resume.\\n\\nCould you please provide it?\"\n",
        "\n",
        "    def handle_chat(self, user_message, history):\n",
        "        \"\"\"Main chat logic handler.\"\"\"\n",
        "\n",
        "        # 1. Verification Phase\n",
        "        if self.state == \"VERIFYING\":\n",
        "            # Save the answer to the PREVIOUS question\n",
        "            if self.current_missing_key:\n",
        "                self.extracted_data[self.current_missing_key] = user_message\n",
        "\n",
        "            # Ask next question\n",
        "            return self.next_question()\n",
        "\n",
        "        # 2. Completed Phase\n",
        "        elif self.state == \"COMPLETE\":\n",
        "            return \"âœ… The profile is already complete! If you want to start over, please upload a new resume.\"\n",
        "\n",
        "        # 3. Waiting for Resume\n",
        "        elif self.state == \"WAITING_FOR_RESUME\":\n",
        "            return \"Please upload your resume using the file button on the right first! ğŸ“„\"\n",
        "\n",
        "        else:\n",
        "            return \"...\"\n",
        "\n",
        "    def finalize_report(self):\n",
        "        \"\"\"Generates the final summary.\"\"\"\n",
        "        json_str = json.dumps(self.extracted_data, indent=2)\n",
        "        response_str = match_jobs(self.extracted_data)\n",
        "        print(response_str)\n",
        "        # Save to local file for download\n",
        "        with open(\"final_candidate_profile.json\", \"w\") as f:\n",
        "            f.write(json_str)\n",
        "        return response_str\n",
        "        # return (f\"âœ… **Profile Building Complete!**\\n\\n\"\n",
        "        #         f\"I have successfully gathered all the data. You can download the JSON file from the Colab file browser.\\n\\n\"\n",
        "        #         f\"```json\\n{json_str}\\n```\")\n",
        "\n",
        "# --- 3. GRADIO UI SETUP ---\n",
        "\n",
        "def create_demo():\n",
        "    agent = ResumeChatBot()\n",
        "\n",
        "    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "        gr.Markdown(\"# ğŸ¤– Job Recommendation AI assistant\")\n",
        "\n",
        "        with gr.Row(scale=1):\n",
        "            with gr.Column(scale=2):\n",
        "                chatbot = gr.Chatbot(\n",
        "                    value=[[None, agent.get_intro_message()]],\n",
        "                    height=500\n",
        "                )\n",
        "                msg = gr.Textbox(\n",
        "                    placeholder=\"Type your answer here...\",\n",
        "                    label=\"Your Response\",\n",
        "                    interactive=True\n",
        "                )\n",
        "\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"Upload Resume\")\n",
        "                file_upload = gr.File(\n",
        "                    label=\"Upload PDF Resume\",\n",
        "                    file_types=[\".pdf\"],\n",
        "                    type=\"filepath\"\n",
        "                )\n",
        "        with gr.Row(scale=2):\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"Status\")\n",
        "                status_box = gr.Markdown(\"Waiting for upload...\")\n",
        "\n",
        "        # EVENT: File Upload\n",
        "        def on_file_upload(file):\n",
        "            response = agent.process_file(file)\n",
        "            return [[None, response]], \"Interactive Mode Active\"\n",
        "\n",
        "        file_upload.upload(on_file_upload, inputs=[file_upload], outputs=[chatbot, status_box])\n",
        "\n",
        "        # EVENT: Chat Message\n",
        "        def on_msg_submit(user_msg, history):\n",
        "            if not user_msg:\n",
        "                return \"\", history, \"\"\n",
        "\n",
        "            bot_response = agent.handle_chat(user_msg, history)\n",
        "\n",
        "            # Update history with user msg and bot response\n",
        "            history.append([user_msg, bot_response])\n",
        "            return \"\", history, bot_response if agent.state == \"COMPLETE\" else \"Processing...\"\n",
        "\n",
        "        msg.submit(on_msg_submit, inputs=[msg, chatbot], outputs=[msg, chatbot, status_box])\n",
        "\n",
        "    return demo\n",
        "\n",
        "# --- 4. LAUNCH ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure dependencies are installed\n",
        "    # !pip install gradio google-generativeai\n",
        "\n",
        "    demo = create_demo()\n",
        "    demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN31Crk1mWJA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}